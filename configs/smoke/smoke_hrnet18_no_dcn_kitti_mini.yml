# This is a training configuration for a simplified version of KITTI. It is just for a quick start,
# all the hyperparameters are not strictly tuned, so the training result is not optimal
_base_: '../_base_/kitti_mono.yml'

batch_size: 8
iters: 10000

train_dataset:
  transforms:
    - type: LoadImage
      reader: pillow
      to_chw: False
    - type: Gt2SmokeTarget
      mode: train
      num_classes: 3
      input_size: [1280, 384]
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

val_dataset:
  transforms:
    - type: LoadImage
      reader: pillow
      to_chw: False
    - type: Gt2SmokeTarget
      mode: val
      num_classes: 3
      input_size: [1280, 384]
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

optimizer:
  type: Adam

lr_scheduler:
  type: MultiStepDecay
  milestones: [5000, 8000]
  learning_rate: 1.25e-4

model:
  type: SMOKE
  backbone:
    type: $paddleseg.HRNet_W18
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
  head:
    type: SMOKEPredictor
    num_classes: 3
    reg_channels: [1, 2, 3, 2, 2]
    num_chanels: 256
    norm_type: "gn"
    in_channels: 270
  depth_ref: [28.01, 16.32]
  # dim_ref is the reference size mentioned in the paper, the order here is [l, h, w]
  dim_ref: [[3.88, 1.63, 1.53], [1.78, 1.70, 0.58], [0.88, 1.73, 0.67]]
  max_detection: 50
  pred_2d: True

export:
  transforms:
    - type: LoadImage
      reader: pillow
      to_chw: False
      to_rgb: True
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
